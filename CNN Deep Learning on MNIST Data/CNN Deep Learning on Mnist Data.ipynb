{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Deep Learning on the MNIST Dataset\n",
    "\n",
    "## By Christopher Hauman\n",
    "<br>\n",
    "\n",
    "This brief guide will cover building a simple Convolutional Neural Network with keras. This is a sequel to my more detailed guide and introduction to Neural Networks, [MLP Deep Learning on the MNIST Dataset](https://github.com/chrisman1015/Deep-Learning/blob/master/MLP%20Deep%20Learning%20on%20MNIST%20Data/MLP%20Deep%20Learning%20on%20Mnist%20Data.ipynb). This will adapt and explain the CNN example in [keras' domumentation](https://keras.io/examples/mnist_cnn/).\n",
    "<br>\n",
    "\n",
    "If you're new to CNNs, I'd highly recommend you check out [Brandon Rohrer](https://youtu.be/FmpDIaiMIeA)'s guide on them, which will give you all the theory you need to know for this implimentation guide. This type of learning also falls under the umbrella of supervised machine learning, which you can learn much more about in my guides [here](https://github.com/chrisman1015/Supervised-Learning).\n",
    "<br>\n",
    "\n",
    "Note: This assumes you have basic knowledge of python data science basics. If you don't, or encounter something you're not familiar with, don't worry! You can get a crash course in my guide, [Cleaning MLB Statcast Data using pandas DataFrames and seaborn Visualization](https://github.com/chrisman1015/Cleaning-Statcast-Data/blob/master/Cleaning%20Statcast%20Data/Cleaning%20Statcast%20Data.ipynb). \n",
    "<br>\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# to make sure gpu is being used for \n",
    "import tensorflow as tf\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing the data as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A key difference between using keras for MLP neural networks and CNN neural networks is the input shape. MLP required the input be a flat image, while CNNs want the data to remain in the rectangular (in this case square) shape. \n",
    "<br>\n",
    "\n",
    "Let's look at the shape of the X_train data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the X_training data is 60000 28x28 images. For CNN input, we specifically need the input data to be in the format (batch, height, width, channels). This means we are lacking one dimension, the channel value. Channels contains the 3 RGB values for color data, but only one for grayscale images. We can fix the shape by assigning a dimension of 1 for the channel of the X_train and X_test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train before reshaping: (60000, 28, 28)\n",
      "X_train after reshaping: (60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print('X_train before reshaping:', X_train.shape)\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"X_train after reshaping:\", X_train.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the X_train and X_test data are in the correct shape. Let's also store the input shape which we'll pass to the first CNN layer similar to the MLP example. We'll also normalize the X data and force the y data into categorical as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get CNN first layer input shape\n",
    "input_shape = X_train[0].shape\n",
    "input_shape\n",
    "\n",
    "# normalize data\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "\n",
    "num_classes = 10\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**kernel_size**\n",
    "-An integer or tuple/list of a single integer, specifying the length of the 1D convolution window.\n",
    "-A 3x3 kernal size means the convolutional window will be a 3x3 square.\n",
    "\n",
    "You can read about the pooling layer [here](http://cs231n.github.io/convolutional-networks/#pool). The argument *pool_size** is a window size similar to **kernel_size**.\n",
    "<br>\n",
    "\n",
    "Other than that, our model will be very similar. The model is still sequential, and will use similar layers and arguments as the MLP model. Note that about halfway through we use **Flatten** to flatten the data into the 1-D arrays that the **Dense** layers use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll fit the model with an early stopping monitor as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.0210 - acc: 0.9928\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.0190 - acc: 0.9934\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.0169 - acc: 0.9944\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.0171 - acc: 0.9945\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.0158 - acc: 0.9947\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.0139 - acc: 0.9952\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.0162 - acc: 0.9949\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.0136 - acc: 0.9956\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.0137 - acc: 0.9954\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0128 - acc: 0.9957\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0119 - acc: 0.9958\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0106 - acc: 0.9965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1de785cfbe0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize early stopping monitor\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 12\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          callbacks = [early_stopping_monitor],\n",
    "          verbose=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.02781256944448555\n",
      "Test accuracy: 0.9938\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at how high the accuracy is! For image classfication, CNNs are an incredibly useful tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
